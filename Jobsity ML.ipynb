{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "java/j2ee/struts/hibernate                220\n",
       "accounting operations                      86\n",
       "fresher                                    86\n",
       "aml/kyc/cdd                                84\n",
       "cdd kyc                                    52\n",
       "java j2ee                                  49\n",
       "routine                                    47\n",
       "oracle                                     43\n",
       "java/spring/hibernate/jsf                  42\n",
       "java                                       31\n",
       "sas                                        27\n",
       "oracle plsql                               25\n",
       "java developer                             25\n",
       "lending and liabilities                    25\n",
       "banking operations                         24\n",
       "core java                                  17\n",
       "sccm                                       15\n",
       "t-24 developer                             15\n",
       "senior software engineer-mednet            15\n",
       "als testing                                15\n",
       "analytical r & d                           13\n",
       "cots developer                             13\n",
       "sr automation testing                      13\n",
       "hadoop                                     12\n",
       "regulatory                                 12\n",
       "testing                                    11\n",
       "java/j2ee                                  10\n",
       "publishing                                  9\n",
       "etl                                         9\n",
       "ra publishing                               9\n",
       "                                         ... \n",
       "java ,j2ee                                  4\n",
       "licensing – ra                              4\n",
       "java, sql                                   3\n",
       "java, xml, struts, hibernate                3\n",
       "11.30 am                                    3\n",
       "tl                                          3\n",
       "java,spring,hibernate                       3\n",
       "analytical r&d                              3\n",
       "biosimillar                                 3\n",
       "java, spring, hibernate                     2\n",
       "submission management                       2\n",
       "lending&liablities                          2\n",
       "lcm -manager                                2\n",
       "production support - sccm                   2\n",
       "java, j2ee                                  2\n",
       "ra label                                    2\n",
       "l & l                                       2\n",
       "manager                                     1\n",
       "biosimilars                                 1\n",
       "sccm-(network, sharepoint,ms exchange)      1\n",
       "basesas program/ reporting                  1\n",
       "sccm – sql                                  1\n",
       "9.30 am                                     1\n",
       "10.00 am                                    1\n",
       "technical lead                              1\n",
       "sccm – sharepoint                           1\n",
       "9.00 am                                     1\n",
       "12.30 pm                                    1\n",
       "tech lead- mednet                           1\n",
       "sccm- networking                            1\n",
       "Name: skillset, Length: 81, dtype: int64"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "import datetime\n",
    "\n",
    "def get_cleaned_date(date):\n",
    "    \"\"\"\n",
    "    Return datetime object from a string\n",
    "    \"\"\"\n",
    "    date = str(date).strip()\n",
    "\n",
    "    if '&' in date:\n",
    "        date = date.split('&')[0].strip()\n",
    "\n",
    "    # Since there are a lot of formats in the data, need to handle all the possible options\n",
    "    date_formats = [\n",
    "        '%d.%m.%Y', '%d.%m.%y', '%d.%m.%y', '%d-%m-%Y', '%d/%m/%y', '%d/%m/%Y', '%d %b %y', '%d-%b -%y',\n",
    "        '%d – %b-%y', '%d -%b -%y'\n",
    "    ]\n",
    "\n",
    "    for date_format in date_formats:\n",
    "        try:\n",
    "            return datetime.datetime.strptime(date, date_format)\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "def get_cleaned_options(string, options, result, target):\n",
    "    if (any(st in string.lower() for st in options)):\n",
    "        target.append(result)\n",
    "    return target\n",
    "\n",
    "spamreader = rawData = pandas.read_csv('Interview.csv')\n",
    "\n",
    "#Remove columns that provide no useful data.\n",
    "cleanData = rawData.drop(['Name(Cand ID)', 'Unnamed: 23', 'Unnamed: 24', 'Unnamed: 25', 'Unnamed: 26', 'Unnamed: 27'], axis = 1)\n",
    "\n",
    "#Remove rows that provide no useful data\n",
    "cleanData = cleanData.drop(1233)\n",
    "\n",
    "#Change column names for easier reference\n",
    "cleanData.columns = [\n",
    "    'date',\n",
    "    'client',\n",
    "    'industry',\n",
    "    'loc',\n",
    "    'pos',\n",
    "    'skillset',\n",
    "    'interview_type',\n",
    "    'gender',\n",
    "    'current_loc',\n",
    "    'job_loc',\n",
    "    'venue_loc',\n",
    "    'native_loc',\n",
    "    'has_permission',\n",
    "    'unscheduled',\n",
    "    'can_call',\n",
    "    'can_hava_alt_number',\n",
    "    'has_cv_print',\n",
    "    'venue',\n",
    "    'call_letter_shared',\n",
    "    'expected_attendance',\n",
    "    'observed_attendance',\n",
    "    'marital_status']\n",
    "\n",
    "#Fix date formats\n",
    "cleanData['date'] = cleanData['date'].map(get_cleaned_date)\n",
    "\n",
    "#Make everything lower case and strip whitespace for more uniform data\n",
    "cleanData = pandas.concat([cleanData[c].astype(str).str.lower() for c in cleanData.columns], axis = 1)\n",
    "cleanData = pandas.concat([cleanData[c].astype(str).str.strip() for c in cleanData.columns], axis = 1)\n",
    "\n",
    "#Merge standard chartered bank and standard chartered bank chennai. job location is specified in another column.\n",
    "cleanData['client'].replace('standard chartered bank chennai', 'standard chartered bank', inplace = True)\n",
    "\n",
    "#aon hewitt, hewitt and aon hewitt gurgaon seem to be the same company, we merge those too\n",
    "cleanData['client'].replace(['hewitt', 'aon hewitt gurgaon'], 'aon hewitt', inplace = True)\n",
    "\n",
    "#Merge similar industry items\n",
    "cleanData['industry'].replace(['it products and services', 'it services'], 'it', inplace = True)\n",
    "\n",
    "#Fix interview types\n",
    "cleanData['interview_type'].replace(['scheduled walk in', 'sceduled walkin'], 'scheduled walkin', inplace=True)\n",
    "\n",
    "#Fix location fields\n",
    "cleanData['loc'].replace(['- cochin-', 'gurgaonr'], ['cochin', 'gurgaon'], inplace = True)\n",
    "cleanData['current_loc'].replace('- cochin-', 'cochin', inplace=True)\n",
    "cleanData['job_loc'].replace('- cochin-', 'cochin', inplace=True)\n",
    "cleanData['venue_loc'].replace('- cochin-', 'cochin', inplace=True)\n",
    "cleanData['native_loc'].replace('- cochin-', 'cochin', inplace=True)\n",
    "cleanData['native_loc'].replace('delhi /ncr', 'delhi', inplace=True)\n",
    "\n",
    "#Fix yes/no/na fields\n",
    "no = ['not yet', 'no dont', 'no- will take it soon', 'no i have only thi number', 'no- i need to check']\n",
    "na = ['nan', 'not sure', 'cant say', 'yet to confirm', 'need to check', 'yet to check', 'havent checked', 'uncertain']\n",
    "cleanData['has_permission'].replace(no, 'no', inplace=True)\n",
    "cleanData['has_permission'].replace(na, 'na', inplace=True)\n",
    "cleanData['unscheduled'].replace(na, 'na', inplace=True)\n",
    "cleanData['can_call'].replace(na, 'na', inplace=True)\n",
    "cleanData['can_call'].replace(no, 'no', inplace=True)\n",
    "cleanData['can_hava_alt_number'].replace(na, 'na', inplace=True)\n",
    "cleanData['can_hava_alt_number'].replace(no, 'no', inplace=True)\n",
    "cleanData['has_cv_print'].replace(na, 'na', inplace=True)\n",
    "cleanData['has_cv_print'].replace(no, 'no', inplace=True)\n",
    "cleanData['venue'].replace(na, 'na', inplace=True)\n",
    "cleanData['venue'].replace(no, 'no', inplace=True)\n",
    "cleanData['call_letter_shared'].replace(na, 'na', inplace=True)\n",
    "cleanData['call_letter_shared'].replace(no, 'no', inplace=True)\n",
    "cleanData['expected_attendance'].replace(na, 'na', inplace=True)\n",
    "cleanData['expected_attendance'].replace(no, 'no', inplace=True)\n",
    "\n",
    "#We will assume that the time means that the candidate is expected at that time\n",
    "cleanData['expected_attendance'].replace('\\d\\d[.:]\\d\\d [ap]m', 'yes', regex=True, inplace=True)\n",
    "\n",
    "cleanData['skillset'].value_counts()\n",
    "#TODO: deal with the skillset field separating each value into keywords and then binarize.\n",
    "#We don't use onehot because we don't know which algorithm will be used yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "col = []\n",
    "data = []\n",
    "for row in spamreader:\n",
    "\n",
    "    date = get_cleaned_date(row[0])\n",
    "    if date is None:\n",
    "        continue\n",
    "    row[0] = date\n",
    "\n",
    "    if (row[2] in ['IT Services', 'IT Products and Services']):\n",
    "        row[2] = 'IT'\n",
    "\n",
    "    row[3] = get_cleaned_location(row[3])\n",
    "\n",
    "    tags = []\n",
    "\n",
    "    if (timeFormat.match(row[5]) is not None):\n",
    "        continue\n",
    "    if (timeFormat.match(row[20]) is not None):\n",
    "        continue\n",
    "\n",
    "    get_cleaned_options(row[5], ['sr', 'senior'], 'Senior', tags)\n",
    "    get_cleaned_options(row[5], ['als testing'], 'ALS Testing', tags)\n",
    "    get_cleaned_options(row[5], ['analytical r & d', 'analytical r&d'], 'Analytical R&D', tags)\n",
    "    get_cleaned_options(row[5], ['accounting operations'], 'Accounting Operations', tags)\n",
    "    get_cleaned_options(row[5], ['banking operations'], 'Banking Operations', tags)\n",
    "    get_cleaned_options(row[5], ['cdd'], 'CDD', tags)\n",
    "    get_cleaned_options(row[5], ['kyc'], 'KYC', tags)\n",
    "    get_cleaned_options(row[5], ['aml'], 'AML', tags)\n",
    "    get_cleaned_options(row[5], ['biosimiliar', 'biosimiliars', 'biosimilars', 'biosimillar'], 'Biosimilar', tags)\n",
    "    get_cleaned_options(row[5], ['cots'], 'COTS', tags)\n",
    "    get_cleaned_options(row[5], ['dot net'], '.Net', tags)\n",
    "    get_cleaned_options(row[5], ['java'], 'Java', tags)\n",
    "    get_cleaned_options(row[5], ['sql'], 'SQL', tags)\n",
    "    get_cleaned_options(row[5], ['j2ee'], 'J2EE', tags)\n",
    "    get_cleaned_options(row[5], ['sapbo'], 'SAPBO', tags)\n",
    "    get_cleaned_options(row[5], ['informatica'], 'Informatica', tags)\n",
    "    get_cleaned_options(row[5], ['struts'], 'Struts', tags)\n",
    "    get_cleaned_options(row[5], ['hibernate'], 'Hibernate', tags)\n",
    "    get_cleaned_options(row[5], ['jsf'], 'JSF', tags)\n",
    "    get_cleaned_options(row[5], ['sas'], 'SAS', tags)\n",
    "    get_cleaned_options(row[5], ['xml'], 'XML', tags)\n",
    "    get_cleaned_options(row[5], ['spring'], 'Spring', tags)\n",
    "    get_cleaned_options(row[5], ['automation testing'], 'Automation Testing', tags)\n",
    "    get_cleaned_options(row[5], ['tech lead', 'technical lead', 'tl'], 'Technical Lead', tags)\n",
    "    get_cleaned_options(row[5], ['l & l', 'lending & liability', 'lending and liabilities', 'lending&liablities'], 'Lending and Liability', tags)\n",
    "    get_cleaned_options(row[5], ['etl'], 'ETL', tags)\n",
    "    get_cleaned_options(row[5], ['fresher'], 'Fresher', tags)\n",
    "    get_cleaned_options(row[5], ['global labelling'], 'Global Labeling', tags)\n",
    "    get_cleaned_options(row[5], ['hadoop'], 'Hadoop', tags)\n",
    "    get_cleaned_options(row[5], ['emea'], 'EMEA', tags)\n",
    "    get_cleaned_options(row[5], ['licensing'], 'Licensing', tags)\n",
    "    get_cleaned_options(row[5], ['manager'], 'Manager', tags)\n",
    "    get_cleaned_options(row[5], ['lcm'], 'Life Cycle Management', tags)\n",
    "    get_cleaned_options(row[5], ['oracle'], 'Oracle', tags)\n",
    "    get_cleaned_options(row[5], ['production'], 'Production', tags)\n",
    "    get_cleaned_options(row[5], ['support'], 'Support', tags)\n",
    "    get_cleaned_options(row[5], ['sccm'], 'SCCM', tags)\n",
    "    get_cleaned_options(row[5], ['sharepoint'], 'Sharepoint', tags)\n",
    "    get_cleaned_options(row[5], ['network'], 'Network', tags)\n",
    "    get_cleaned_options(row[5], ['ms exchange'], 'MS Exchange', tags)\n",
    "    get_cleaned_options(row[5], ['product control'], 'Product Control', tags)\n",
    "    get_cleaned_options(row[5], ['publishing'], 'Publishing', tags)\n",
    "    get_cleaned_options(row[5], ['label'], 'Label', tags)\n",
    "    get_cleaned_options(row[5], ['regulatory'], 'Regulatory', tags)\n",
    "    get_cleaned_options(row[5], ['routine'], 'Routine', tags)\n",
    "    get_cleaned_options(row[5], ['analyst'], 'Analist', tags)\n",
    "    get_cleaned_options(row[5], ['software engineer'], 'Software Engineer', tags)\n",
    "    get_cleaned_options(row[5], ['mednet'], 'Mednet', tags)\n",
    "    get_cleaned_options(row[5], ['submission management'], 'Submission Management', tags)\n",
    "    get_cleaned_options(row[5], ['t-24 developer'], 'T-24 Developer', tags)\n",
    "    get_cleaned_options(row[5], ['generic drugs'], 'Generic Drugs', tags)\n",
    "    get_cleaned_options(row[5], ['testing'], 'Testing', tags)\n",
    "    if (all(st in row[5] for st in ['BaseSAS', 'Program'])):\n",
    "        tags.append('BaseSAS Program')\n",
    "    if (all(st in row[5] for st in ['BaseSAS', 'Reporting'])):\n",
    "        tags.append('BaseSAS Reporting')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
