{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawData = pandas.read_csv('Interview.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import datetime\n",
    "\n",
    "def get_cleaned_date(date):\n",
    "    \"\"\"\n",
    "    Return datetime object from a string\n",
    "    \"\"\"\n",
    "    date = str(date).strip()\n",
    "\n",
    "    if '&' in date:\n",
    "        date = date.split('&')[0].strip()\n",
    "\n",
    "    # Since there are a lot of formats in the data, need to handle all the possible options\n",
    "    date_formats = [\n",
    "        '%d.%m.%Y', '%d.%m.%y', '%d.%m.%y', '%d-%m-%Y', '%d/%m/%y', '%d/%m/%Y', '%d %b %y', '%d-%b -%y',\n",
    "        '%d – %b-%y', '%d -%b -%y'\n",
    "    ]\n",
    "\n",
    "    for date_format in date_formats:\n",
    "        try:\n",
    "            return datetime.datetime.strptime(date, date_format)\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "#Remove columns that provide no useful data.\n",
    "cleanData = rawData.drop(['Name(Cand ID)', 'Unnamed: 23', 'Unnamed: 24', 'Unnamed: 25', 'Unnamed: 26', 'Unnamed: 27'], axis = 1)\n",
    "\n",
    "#Remove rows that provide no useful data\n",
    "cleanData = cleanData.drop(1233)\n",
    "\n",
    "#Change column names for easier reference\n",
    "cleanData.columns = [\n",
    "    'date',\n",
    "    'client',\n",
    "    'industry',\n",
    "    'loc',\n",
    "    'pos',\n",
    "    'skillset',\n",
    "    'interview_type',\n",
    "    'gender',\n",
    "    'current_loc',\n",
    "    'job_loc',\n",
    "    'venue_loc',\n",
    "    'native_loc',\n",
    "    'has_permission',\n",
    "    'unscheduled',\n",
    "    'can_call',\n",
    "    'can_have_alt_number',\n",
    "    'has_cv_print',\n",
    "    'venue',\n",
    "    'call_letter_shared',\n",
    "    'expected_attendance',\n",
    "    'observed_attendance',\n",
    "    'marital_status']\n",
    "\n",
    "#Fix date formats\n",
    "cleanData['date'] = cleanData['date'].map(get_cleaned_date)\n",
    "\n",
    "#We know the date range should be between sep 2014 and jan 2017 so we eliminate all records outside of that range.\n",
    "cleanData = cleanData[(cleanData['date'] >'2014-09-01') & (cleanData['date'] < '2017-01-31')]\n",
    "\n",
    "\n",
    "#Make everything lower case and strip whitespace padding for more uniform data\n",
    "cleanData = pandas.concat([cleanData[c].astype(str).str.lower() for c in cleanData.columns], axis = 1)\n",
    "cleanData = pandas.concat([cleanData[c].astype(str).str.strip() for c in cleanData.columns], axis = 1)\n",
    "\n",
    "#Merge standard chartered bank and standard chartered bank chennai. job location is specified in another column.\n",
    "cleanData['client'].replace('standard chartered bank chennai', 'standard chartered bank', inplace = True)\n",
    "\n",
    "#aon hewitt, hewitt and aon hewitt gurgaon seem to be the same company, we merge those too\n",
    "cleanData['client'].replace(['hewitt', 'aon hewitt gurgaon'], 'aon hewitt', inplace = True)\n",
    "\n",
    "#Merge similar industry items\n",
    "cleanData['industry'].replace(['it products and services', 'it services'], 'it', inplace = True)\n",
    "\n",
    "#Fix interview types\n",
    "cleanData['interview_type'].replace(['scheduled walk in', 'sceduled walkin'], 'scheduled walkin', inplace=True)\n",
    "\n",
    "#Fix location fields\n",
    "cleanData['loc'].replace(['- cochin-', 'gurgaonr'], ['cochin', 'gurgaon'], inplace = True)\n",
    "cleanData['current_loc'].replace('- cochin-', 'cochin', inplace=True)\n",
    "cleanData['job_loc'].replace('- cochin-', 'cochin', inplace=True)\n",
    "cleanData['venue_loc'].replace('- cochin-', 'cochin', inplace=True)\n",
    "cleanData['native_loc'].replace('- cochin-', 'cochin', inplace=True)\n",
    "cleanData['native_loc'].replace('delhi /ncr', 'delhi', inplace=True)\n",
    "\n",
    "#We will assume that the time means that the candidate is expected at that time\n",
    "time_pattern = '\\d?\\d[.:]\\d\\d [ap]m'\n",
    "cleanData['expected_attendance'].replace(time_pattern, 'yes', regex=True, inplace=True)\n",
    "\n",
    "#Normalize yes/no/na fields\n",
    "features= ['has_permission', 'unscheduled', 'can_call', 'can_have_alt_number', 'has_cv_print', 'venue', 'call_letter_shared', 'expected_attendance', 'observed_attendance']\n",
    "no = ['no', 'not yet', 'no dont', 'no- will take it soon', 'no i have only thi number', 'no- i need to check']\n",
    "na = ['na', 'nan', 'not sure', 'cant say', 'yet to confirm', 'need to check', 'yet to check', 'havent checked', 'uncertain']\n",
    "\n",
    "for feature in features:\n",
    "    cleanData[feature].replace(no, -1, inplace=True)\n",
    "    cleanData[feature].replace(na, 0, inplace=True)\n",
    "    cleanData[feature].replace('yes', 1, inplace=True)\n",
    "    \n",
    "#Normalize gender column\n",
    "cleanData['gender'].replace('male', 1, inplace=True)\n",
    "cleanData['gender'].replace('female', -1, inplace=True)\n",
    "\n",
    "\n",
    "#We drop values that look like dateTime as they make no sense in the skillset column.\n",
    "filterSeries = cleanData['skillset'].str.contains(time_pattern, regex=True)\n",
    "cleanData = cleanData[~filterSeries]\n",
    "\n",
    "#Let's give the field some somblance of an uniform format for easier processing\n",
    "cleanData['skillset'].replace([\n",
    "    '/', ' ?, ?', ' developer', 'r & d', 'sccm ?- ?', ' – ra'\n",
    "], [\n",
    "    ',', ',', '',  'r&d', 'sccm,',  ''\n",
    "], inplace=True, regex=True)\n",
    "cleanData['skillset'].replace([\n",
    "    'cdd kyc',\n",
    "    'java j2ee',\n",
    "    'oracle plsql',\n",
    "    'core java',\n",
    "    'senior software engineer-mednet',\n",
    "    'sr automation testing',\n",
    "    'tech lead-mednet',\n",
    "    'ra publishing',\n",
    "    'java jsf',\n",
    "    'java,j2ee,core java',\n",
    "    'java tech lead',\n",
    "    'automation testing java',\n",
    "    '- sapbo,informatica',\n",
    "    'production support - sccm',\n",
    "    'tech lead- mednet',\n",
    "    'technical lead',\n",
    "    'senior analyst',\n",
    "    'sccm – sharepoint',\n",
    "    'sccm – sql',\n",
    "    'tl',\n",
    "    'sccm,(network,sharepoint,ms exchange)',\n",
    "    'java-sas',\n",
    "    'lcm -manager',\n",
    "    'basesas_program,reporting'\n",
    "], [\n",
    "    'cdd,kyc',\n",
    "    'java,j2ee',\n",
    "    'plsql',\n",
    "    'java',\n",
    "    'senior,developer,mednet',\n",
    "    'senior,automation,testing',\n",
    "    'tech lead,mednet',\n",
    "    'publishing',\n",
    "    'java,jsf',\n",
    "    'java,j2ee',\n",
    "    'java,tech lead',\n",
    "    'java,automation,testing',\n",
    "    'sapbo,informatica',\n",
    "    'sccm,production support',\n",
    "    'tech lead,mednet',\n",
    "    'tech lead',\n",
    "    'senior,analyst',\n",
    "    'sccm,sharepoint',\n",
    "    'sccm,sql',\n",
    "    'tech lead',\n",
    "    'sccm,network,sharepoint,ms_exchange',\n",
    "    'java,sas',\n",
    "    'lcm manager',\n",
    "    'baseSAS'\n",
    "    \n",
    "], inplace=True)\n",
    "cleanData['skillset'].replace([\n",
    "    'lending&liablities',\n",
    "    'l & l',\n",
    "    'lending & liability'\n",
    "], 'lending and liabilities', inplace=True)\n",
    "cleanData['skillset'].replace(['biosimiliars', 'biosimillar'], 'biosimilars', inplace=True)\n",
    "cleanData['skillset'].replace(' ',  '_', regex=True, inplace=True)\n",
    "\n",
    "#Lets binarize each item into categories\n",
    "skillset = cleanData.skillset.str.split(',', expand=True).stack()\n",
    "dummies = pandas.get_dummies(skillset, prefix='skillset').groupby(level=0).sum()\n",
    "\n",
    "cleanData = cleanData.join(dummies)\n",
    "\n",
    "#We drop skillset as it is now encoded\n",
    "cleanData.drop('skillset', axis=1, inplace=True)\n",
    "\n",
    "#Encode other categorical features using oneHot\n",
    "features = ['loc', 'pos', 'client', 'industry', 'interview_type', 'current_loc', 'job_loc', 'venue_loc', 'native_loc', 'marital_status']\n",
    "\n",
    "for feature in features:\n",
    "    dummies = pandas.get_dummies(cleanData[feature], prefix=feature)\n",
    "    cleanData.drop(feature, axis=1, inplace=True)\n",
    "    cleanData = cleanData.join(dummies)\n",
    "\n",
    "cleanData.to_excel('excel_clean.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
